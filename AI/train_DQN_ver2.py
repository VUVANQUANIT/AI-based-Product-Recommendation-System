import numpy as np
import pymysql
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import os
from collections import deque
import random
import time

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# K·∫øt n·ªëi MySQL
def get_data():
    try:
        conn = pymysql.connect(host='localhost', user='root', password='', database='thoitrang')
        cursor = conn.cursor()
        cursor.execute("SELECT user_id, product_id, action_type, score, timestamp FROM user_behavior ORDER BY user_id, timestamp")
        data = cursor.fetchall()
        conn.close()
        logging.info("‚úÖ ƒê√£ l·∫•y d·ªØ li·ªáu t·ª´ MySQL")
        return data
    except pymysql.Error as e:
        logging.error(f"‚ùå L·ªói k·∫øt n·ªëi MySQL: {e}")
        return []

# M√¥ h√¨nh DQN
class DQNModel:
    def __init__(self, state_dim, action_dim):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.model = self._build_model()
        self.target_model = keras.models.clone_model(self.model)
        self.target_model.set_weights(self.model.get_weights())
        self.epsilon = 1.0  # Kh·ªüi t·∫°o epsilon cho exploration
        self.epsilon_min = 0.1
        self.epsilon_decay = 0.99

    def _build_model(self):
        model = keras.Sequential([
            layers.Input(shape=(self.state_dim,)),
            layers.Dense(128, activation="relu"),
            layers.Dense(128, activation="relu"),
            layers.Dense(self.action_dim, activation="linear")
        ])
        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), 
                      loss=keras.losses.MeanSquaredError())
        return model

    def predict(self, states):
        return self.model.predict(states, verbose=0)

    def get_action(self, state):
        if random.random() < self.epsilon:
            return random.randint(0, self.action_dim - 1)
        q_values = self.predict(np.array([state]))[0]
        return np.argmax(q_values)

    def train(self, states, targets, batch_size=32):
        self.model.fit(states, targets, batch_size=batch_size, epochs=1, verbose=0)
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

    def update_target(self):
        self.target_model.set_weights(self.model.get_weights())

    def save(self, filename="dqn_model.keras"):
        self.model.save(filename)
        with open("dqn_config.json", "w") as f:
            json.dump({"state_dim": self.state_dim, "action_dim": self.action_dim}, f)
        logging.info(f" ƒê√£ l∆∞u m√¥ h√¨nh v√†o {filename}")

    def load(self, filename="dqn_model.keras"):
        self.model = keras.models.load_model(filename)
        self.target_model = keras.models.clone_model(self.model)
        self.target_model.set_weights(self.model.get_weights())
        with open("dqn_config.json", "r") as f:
            config = json.load(f)
            self.state_dim = config["state_dim"]
            self.action_dim = config["action_dim"]
        logging.info(f" ƒê√£ load m√¥ h√¨nh t·ª´ {filename}")

# D·ªØ li·ªáu to√†n c·ª•c
global_data = {
    "user_dict": {},
    "product_dict": {},
    "state_dim": 0,
    "action_dim": 0,
    "last_updated": 0
}

def update_global_data(data=None):
    if data is None:
        data = get_data()
    global_data["user_dict"] = {uid: idx for idx, uid in enumerate(sorted(set(d[0] for d in data)))}
    global_data["product_dict"] = {pid: idx for idx, pid in enumerate(sorted(set(d[1] for d in data)))}
    global_data["state_dim"] = len(global_data["user_dict"]) + len(global_data["product_dict"])
    global_data["action_dim"] = len(global_data["product_dict"])
    global_data["last_updated"] = time.time()
    logging.info(f"ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu to√†n c·ª•c: state_dim={global_data['state_dim']}, action_dim={global_data['action_dim']}")

def get_state(user_id, last_product_id=None):
    state = np.zeros(global_data["state_dim"])
    if user_id in global_data["user_dict"]:
        state[global_data["user_dict"][user_id]] = 1
    if last_product_id in global_data["product_dict"]:
        state[len(global_data["user_dict"]) + global_data["product_dict"][last_product_id]] = 1
    return state

# Hu·∫•n luy·ªán DQN v·ªõi Experience Replay
def train_dqn(model, data, episodes=10, gamma=0.9, batch_size=32, replay_size=1000):
    if not data:
        logging.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán")
        return

    replay_buffer = deque(maxlen=replay_size)
    user_history = {}

    # Chu·∫©n b·ªã replay buffer
    for user_id, product_id, _, reward, _ in data:
        if user_id not in user_history:
            user_history[user_id] = []
        state = get_state(user_id, user_history[user_id][-1] if user_history[user_id] else None)
        next_state = get_state(user_id, product_id)
        action = global_data["product_dict"][product_id]
        replay_buffer.append((state, action, reward, next_state))
        user_history[user_id].append(product_id)

    # Hu·∫•n luy·ªán
    for episode in range(episodes):
        if len(replay_buffer) < batch_size:
            logging.warning(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu trong replay buffer: {len(replay_buffer)}/{batch_size}")
            continue
        batch = random.sample(replay_buffer, batch_size)
        states = np.array([x[0] for x in batch])
        actions = [x[1] for x in batch]
        rewards = [x[2] for x in batch]
        next_states = np.array([x[3] for x in batch])

        q_targets = model.predict(states)
        q_next = model.target_model.predict(next_states)
        for i in range(batch_size):
            q_targets[i, actions[i]] = rewards[i] + gamma * np.max(q_next[i])
        model.train(states, q_targets, batch_size)
        model.update_target()
        logging.info(f"üîÑ Episode {episode + 1}/{episodes}")
    
    model.save()

# Kh·ªüi t·∫°o m√¥ h√¨nh
update_global_data()
model = DQNModel(global_data["state_dim"], global_data["action_dim"])
if os.path.exists("dqn_model.keras") and os.path.exists("dqn_config.json"):
    with open("dqn_config.json", "r") as f:
        config = json.load(f)
        if config["state_dim"] == global_data["state_dim"] and config["action_dim"] == global_data["action_dim"]:
            model.load()
            logging.info(f"‚úÖ ƒê√£ load m√¥ h√¨nh v·ªõi state_dim={global_data['state_dim']}")
        else:
            # T·∫°o m√¥ h√¨nh t·∫°m ƒë·ªÉ load tr·ªçng s·ªë c≈©
            old_model = DQNModel(config["state_dim"], config["action_dim"])
            old_model.load()
            old_weights = old_model.model.get_weights()
            new_weights = model.model.get_weights()
            # Chuy·ªÉn giao tr·ªçng s·ªë t∆∞∆°ng th√≠ch
            for i in range(len(old_weights)):
                if old_weights[i].shape == new_weights[i].shape:
                    new_weights[i] = old_weights[i]
                else:
                    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho t·∫ßng ƒë·∫ßu ti√™n n·∫øu state_dim thay ƒë·ªïi
                    if i == 0:  # T·∫ßng ƒë·∫ßu ti√™n (weights)
                        old_shape = old_weights[i].shape
                        new_weights[i][:old_shape[0], :old_shape[1]] = old_weights[i]
                    elif i == 1:  # Bias c·ªßa t·∫ßng ƒë·∫ßu ti√™n
                        new_weights[i][:old_weights[i].shape[0]] = old_weights[i]
            model.model.set_weights(new_weights)
            logging.info(f"‚úÖ Chuy·ªÉn giao tr·ªçng s·ªë t·ª´ m√¥ h√¨nh c≈© (state_dim={config['state_dim']}) sang m√¥ h√¨nh m·ªõi (state_dim={global_data['state_dim']})")
else:
    logging.info(f"‚úÖ T·∫°o m√¥ h√¨nh m·ªõi v·ªõi state_dim={global_data['state_dim']}")

# Hu·∫•n luy·ªán ban ƒë·∫ßu
data = get_data()
train_dqn(model, data, episodes=10)

# API Flask
app = Flask(__name__)
CORS(app)

@app.route('/recommend', methods=['GET'])
def recommend():
    global model
    try:
        if time.time() - global_data["last_updated"] > 60:  # C·∫≠p nh·∫≠t m·ªói 60 gi√¢y
            old_state_dim = global_data["state_dim"]
            update_global_data()
            if model.state_dim != global_data["state_dim"]:
                logging.warning(f"‚ö†Ô∏è state_dim thay ƒë·ªïi: c≈©={model.state_dim}, m·ªõi={global_data['state_dim']}")
                old_model = model
                model = DQNModel(global_data["state_dim"], global_data["action_dim"])
                # Chuy·ªÉn giao tr·ªçng s·ªë
                old_weights = old_model.model.get_weights()
                new_weights = model.model.get_weights()
                for i in range(len(old_weights)):
                    if old_weights[i].shape == new_weights[i].shape:
                        new_weights[i] = old_weights[i]
                    else:
                        if i == 0:
                            old_shape = old_weights[i].shape
                            new_weights[i][:old_shape[0], :old_shape[1]] = old_weights[i]
                        elif i == 1:
                            new_weights[i][:old_weights[i].shape[0]] = old_weights[i]
                model.model.set_weights(new_weights)
                logging.info("‚úÖ ƒê√£ chuy·ªÉn giao tr·ªçng s·ªë sang m√¥ h√¨nh m·ªõi")

        user_id = request.args.get('user_id')
        user_id = int(user_id) if user_id and user_id.isdigit() else None
        if not user_id or user_id not in global_data["user_dict"]:
            logging.warning(f"‚ö†Ô∏è User {user_id} kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu")
            return jsonify({"user_id": user_id, "recommendations": []})

        # L·∫•y s·∫£n ph·∫©m cu·ªëi c√πng c·ªßa ng∆∞·ªùi d√πng
        conn = pymysql.connect(host='localhost', user='root', password='', database='thoitrang')
        cursor = conn.cursor()
        cursor.execute("SELECT product_id FROM user_behavior WHERE user_id = %s ORDER BY timestamp DESC LIMIT 1", (user_id,))
        last_product = cursor.fetchone()
        conn.close()

        state = get_state(user_id, last_product[0] if last_product else None)
        q_values = model.predict(np.array([state]))[0]
        product_array = np.array(list(global_data["product_dict"].keys()))
        recommended_products = product_array[np.argsort(q_values)[::-1][:200]].tolist()  # Top 10 s·∫£n ph·∫©m

        logging.info(f"‚úÖ G·ª£i √Ω cho user {user_id}: {recommended_products}")
        return jsonify({"user_id": user_id, "recommendations": recommended_products})

    except Exception as e:
        logging.error(f"‚ùå L·ªói: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/update_policy', methods=['POST'])
def update_policy():
    global model
    try:
        data = request.json
        user_id = int(data.get("user_id"))
        product_id = data.get("product_id")
        reward = float(data.get("reward"))

        # C·∫≠p nh·∫≠t d·ªØ li·ªáu to√†n c·ª•c
        if time.time() - global_data["last_updated"] > 60:
            old_state_dim = global_data["state_dim"]
            update_global_data()
            if model.state_dim != global_data["state_dim"]:
                logging.warning(f"‚ö†Ô∏è state_dim thay ƒë·ªïi: c≈©={model.state_dim}, m·ªõi={global_data['state_dim']}")
                old_model = model
                model = DQNModel(global_data["state_dim"], global_data["action_dim"])
                # Chuy·ªÉn giao tr·ªçng s·ªë
                old_weights = old_model.model.get_weights()
                new_weights = model.model.get_weights()
                for i in range(len(old_weights)):
                    if old_weights[i].shape == new_weights[i].shape:
                        new_weights[i] = old_weights[i]
                    else:
                        if i == 0:
                            old_shape = old_weights[i].shape
                            new_weights[i][:old_shape[0], :old_shape[1]] = old_weights[i]
                        elif i == 1:
                            new_weights[i][:old_weights[i].shape[0]] = old_weights[i]
                model.model.set_weights(new_weights)
                logging.info("‚úÖ ƒê√£ chuy·ªÉn giao tr·ªçng s·ªë sang m√¥ h√¨nh m·ªõi")

        if user_id not in global_data["user_dict"] or product_id not in global_data["product_dict"]:
            return jsonify({"error": "User ho·∫∑c s·∫£n ph·∫©m kh√¥ng t·ªìn t·∫°i"}), 400

        conn = pymysql.connect(host='localhost', user='root', password='', database='thoitrang')
        cursor = conn.cursor()
        cursor.execute("SELECT product_id FROM user_behavior WHERE user_id = %s ORDER BY timestamp DESC LIMIT 1", (user_id,))
        last_product = cursor.fetchone()
        conn.close()

        state = get_state(user_id, last_product[0] if last_product else None)
        next_state = get_state(user_id, product_id)
        action = global_data["product_dict"][product_id]

        q_targets = model.predict(np.array([state]))
        q_next = model.target_model.predict(np.array([next_state]))
        q_targets[0, action] = reward + 0.9 * np.max(q_next[0])
        model.train(np.array([state]), q_targets, batch_size=1)
        model.update_target()

        product_array = np.array(list(global_data["product_dict"].keys()))
        recommendations = product_array[np.argsort(model.predict(np.array([next_state]))[0])[::-1][:200]].tolist()

        model.save()
        logging.info(f"‚úÖ C·∫≠p nh·∫≠t policy cho user {user_id}: {recommendations}")
        return jsonify({"user_id": user_id, "product_id": product_id, "recommendations": recommendations})

    except Exception as e:
        logging.error(f"‚ùå L·ªói: {e}")
        return jsonify({"error": str(e)}), 500
# s·ª≠ d·ª•ng trong b√°o c√°o
if __name__ == '__main__':
    app.run(debug=True)